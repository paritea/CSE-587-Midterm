{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Ablation Study* : Early Stopping\n",
    "\n",
    "Implementing an early stop mechanism on the baseline model chosen by us\n",
    "\n",
    "By - Darshan Chudiwal and Yash Priyadarshi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-28T03:50:35.601388Z",
     "iopub.status.busy": "2025-02-28T03:50:35.601070Z",
     "iopub.status.idle": "2025-02-28T03:51:05.496123Z",
     "shell.execute_reply": "2025-02-28T03:51:05.495467Z",
     "shell.execute_reply.started": "2025-02-28T03:50:35.601335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchmetrics\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T03:51:05.497258Z",
     "iopub.status.busy": "2025-02-28T03:51:05.496824Z",
     "iopub.status.idle": "2025-02-28T03:51:32.179738Z",
     "shell.execute_reply": "2025-02-28T03:51:32.178755Z",
     "shell.execute_reply.started": "2025-02-28T03:51:05.497236Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>topic</th>\n",
       "      <th>source</th>\n",
       "      <th>bias</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>authors</th>\n",
       "      <th>content</th>\n",
       "      <th>content_original</th>\n",
       "      <th>source_url</th>\n",
       "      <th>bias_text</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>immigration</td>\n",
       "      <td>National Review</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.nationalreview.com/2018/12/governm...</td>\n",
       "      <td>shutdown theater again</td>\n",
       "      <td>2018-12-12</td>\n",
       "      <td>Kevin D. Williamson, Kyle Smith, Andrew C. Mcc...</td>\n",
       "      <td>President Trump and Senate Minority Leader Chu...</td>\n",
       "      <td>president trump and senate minority leader chu...</td>\n",
       "      <td>www.nationalreview.com</td>\n",
       "      <td>right</td>\n",
       "      <td>zl7kc7EmAyIdUMIo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>culture</td>\n",
       "      <td>Yahoo! The 360</td>\n",
       "      <td>1</td>\n",
       "      <td>https://news.yahoo.com/can-the-developing-worl...</td>\n",
       "      <td>can the developing world endure the coronavirus</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>Mike Bebernes</td>\n",
       "      <td>“ The 360 ” shows you diverse perspectives on ...</td>\n",
       "      <td>the 360 shows you diverse perspectives on the ...</td>\n",
       "      <td>www.news.yahoo.com</td>\n",
       "      <td>center</td>\n",
       "      <td>xpbjYTJYPdlw6HmJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        topic           source  bias  \\\n",
       "0           0  immigration  National Review     2   \n",
       "1           1      culture   Yahoo! The 360     1   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.nationalreview.com/2018/12/governm...   \n",
       "1  https://news.yahoo.com/can-the-developing-worl...   \n",
       "\n",
       "                                             title        date  \\\n",
       "0                           shutdown theater again  2018-12-12   \n",
       "1  can the developing world endure the coronavirus  2020-06-30   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Kevin D. Williamson, Kyle Smith, Andrew C. Mcc...   \n",
       "1                                      Mike Bebernes   \n",
       "\n",
       "                                             content  \\\n",
       "0  President Trump and Senate Minority Leader Chu...   \n",
       "1  “ The 360 ” shows you diverse perspectives on ...   \n",
       "\n",
       "                                    content_original              source_url  \\\n",
       "0  president trump and senate minority leader chu...  www.nationalreview.com   \n",
       "1  the 360 shows you diverse perspectives on the ...      www.news.yahoo.com   \n",
       "\n",
       "  bias_text                ID  \n",
       "0     right  zl7kc7EmAyIdUMIo  \n",
       "1    center  xpbjYTJYPdlw6HmJ  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_PATH = '/kaggle/input/bias-of-us-news-media-houses/Train.xlsx'\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Clean the input text by removing URLs, 'RT', special characters, and extra whitespace.\"\"\"\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)  # remove URLs\n",
    "    text = re.sub(r\"RT \", \" \", text)       # remove 'RT'\n",
    "    text = re.sub(r\"[^a-zA-Z\\'\\.\\,\\d\\s]\", \" \", text)  # remove unwanted characters\n",
    "    text = re.sub(r'\\t', ' ', text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def load_and_preprocess_data(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_excel(path, engine='openpyxl')\n",
    "    for col in ['content_original', 'title']:\n",
    "        # Use only the first section if split by the delimiter\n",
    "        df[col] = df[col].str.split(' \\n\\n---\\n\\n').str[0]\n",
    "        # Replace dashes and punctuation, then lower the text\n",
    "        df[col] = (df[col]\n",
    "                   .str.replace('-', ' ')\n",
    "                   .str.replace('[^\\w\\s]', '', regex=True)\n",
    "                   .str.replace('\\n', ' ')\n",
    "                   .str.lower())\n",
    "        df[col] = df[col].apply(clean_text)\n",
    "    return df\n",
    "\n",
    "# Load and preview the data\n",
    "df_train = load_and_preprocess_data(TRAIN_PATH)\n",
    "df_train.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T03:51:32.181068Z",
     "iopub.status.busy": "2025-02-28T03:51:32.180631Z",
     "iopub.status.idle": "2025-02-28T03:53:06.816210Z",
     "shell.execute_reply": "2025-02-28T03:53:06.815397Z",
     "shell.execute_reply.started": "2025-02-28T03:51:32.181047Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec model from binary file (this may take several minutes)...\n",
      "Saving cached version...\n",
      "Word2Vec embeddings loaded: vocab size = 3000001, embedding dim = 300\n"
     ]
    }
   ],
   "source": [
    "word2vec_model_path = '/kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin'\n",
    "cached_kv_path = 'word2vec_model.kv'\n",
    "\n",
    "if os.path.exists(cached_kv_path):\n",
    "    print(\"Loading cached Word2Vec model...\")\n",
    "    w2v_model = KeyedVectors.load(cached_kv_path, mmap='r')\n",
    "else:\n",
    "    print(\"Loading Word2Vec model from binary file (this may take several minutes)...\")\n",
    "    w2v_model = KeyedVectors.load_word2vec_format(word2vec_model_path, binary=True)\n",
    "    print(\"Saving cached version...\")\n",
    "    w2v_model.save(cached_kv_path)\n",
    "\n",
    "# Build vocabulary mapping and embedding matrix.\n",
    "# Reserve index 0 for unknown words.\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "UNK_INDEX = 0\n",
    "# Create vocabulary mapping, shifting indices by 1 so that index 0 is reserved for UNK.\n",
    "word2vec_vocab = {word: idx + 1 for word, idx in w2v_model.key_to_index.items()}\n",
    "vocab_size = len(word2vec_vocab) + 1\n",
    "embedding_dim = w2v_model.vector_size  # typically 300\n",
    "\n",
    "# Build the embedding matrix (row 0 will remain zeros for UNK)\n",
    "embedding_matrix = torch.zeros(vocab_size, embedding_dim)\n",
    "for word, idx in word2vec_vocab.items():\n",
    "    embedding_matrix[idx] = torch.tensor(w2v_model[word])\n",
    "    \n",
    "print(f\"Word2Vec embeddings loaded: vocab size = {vocab_size}, embedding dim = {embedding_dim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T03:53:06.818028Z",
     "iopub.status.busy": "2025-02-28T03:53:06.817779Z",
     "iopub.status.idle": "2025-02-28T03:53:06.822544Z",
     "shell.execute_reply": "2025-02-28T03:53:06.821745Z",
     "shell.execute_reply.started": "2025-02-28T03:53:06.818007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def basic_tokenizer(text: str) -> list:\n",
    "    \"\"\"Tokenize text by splitting on whitespace.\"\"\"\n",
    "    return text.split()\n",
    "\n",
    "def tokenize_and_pad(text: str, max_len: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Tokenizes the input text and converts tokens to indices using the Word2Vec vocabulary.\n",
    "    Unknown tokens are assigned index 0. The sequence is padded or truncated to max_len.\n",
    "    \"\"\"\n",
    "    tokens = basic_tokenizer(text)\n",
    "    indices = [word2vec_vocab.get(token, UNK_INDEX) for token in tokens]\n",
    "    padded = indices[:max_len] + [0] * max(0, max_len - len(indices))\n",
    "    return torch.tensor(padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T03:53:06.823598Z",
     "iopub.status.busy": "2025-02-28T03:53:06.823418Z",
     "iopub.status.idle": "2025-02-28T03:53:06.905938Z",
     "shell.execute_reply": "2025-02-28T03:53:06.904974Z",
     "shell.execute_reply.started": "2025-02-28T03:53:06.823582Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (21272, 13) Val shape: (5318, 13)\n"
     ]
    }
   ],
   "source": [
    "class BiasDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, max_sentence_length: int):\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "  \n",
    "    def __getitem__(self, index: int) -> dict:\n",
    "        row = self.data.iloc[index]\n",
    "        body = tokenize_and_pad(row['content_original'], self.max_sentence_length)\n",
    "        title = tokenize_and_pad(row['title'], self.max_sentence_length)\n",
    "        # Assuming 'bias' is an integer label\n",
    "        label = torch.tensor(row['bias'], dtype=torch.long)\n",
    "        return {\"body\": body, \"title\": title, \"labels\": label}\n",
    "\n",
    "class BiasDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_df: pd.DataFrame, val_df: pd.DataFrame, max_sentence_length: int, batch_size: int):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = BiasDataset(self.train_df, self.max_sentence_length)\n",
    "        self.val_dataset = BiasDataset(self.val_df, self.max_sentence_length)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size,\n",
    "                          shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size,\n",
    "                          shuffle=False, num_workers=4, drop_last=False)\n",
    "\n",
    "# Split the dataset (e.g., 80% train, 20% validation)\n",
    "train_df, val_df = train_test_split(df_train, test_size=0.2, random_state=42)\n",
    "print(\"Train shape:\", train_df.shape, \"Val shape:\", val_df.shape)\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "MAX_LEN = 120  # Adjust based on your text lengths\n",
    "data_module = BiasDataModule(train_df, val_df, max_sentence_length=MAX_LEN, batch_size=BATCH_SIZE)\n",
    "data_module.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T03:53:06.907242Z",
     "iopub.status.busy": "2025-02-28T03:53:06.906917Z",
     "iopub.status.idle": "2025-02-28T03:53:06.994604Z",
     "shell.execute_reply": "2025-02-28T03:53:06.993952Z",
     "shell.execute_reply.started": "2025-02-28T03:53:06.907214Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LitBiasModel(\n",
      "  (embedding): Embedding(3000001, 300)\n",
      "  (bilstm): LSTM(300, 200, num_layers=2, batch_first=True, dropout=0.4, bidirectional=True)\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.4, inplace=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=64, bias=True)\n",
      "    (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Dropout(p=0.4, inplace=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (7): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): Dropout(p=0.4, inplace=False)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=32, out_features=3, bias=True)\n",
      "  )\n",
      "  (loss_fn): CrossEntropyLoss()\n",
      "  (train_acc): MulticlassAccuracy()\n",
      "  (val_acc): MulticlassAccuracy()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LitBiasModel(pl.LightningModule):\n",
    "    def __init__(self, embedding_matrix: torch.Tensor, num_classes: int,\n",
    "                 embed_dim: int, hidd_dim: int, num_layers: int = 2, lr: float = 1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"embedding_matrix\"])\n",
    "        # Frozen embedding layer using pretrained Word2Vec embeddings\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=True)\n",
    "        \n",
    "        # Shared bidirectional LSTM layer\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidd_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.4,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Classification head (feedforward network)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidd_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.train_acc = torchmetrics.Accuracy(num_classes=num_classes, task=\"multiclass\")\n",
    "        self.val_acc = torchmetrics.Accuracy(num_classes=num_classes, task=\"multiclass\")\n",
    "        self._train_losses = []\n",
    "        self._val_losses = []\n",
    "        # Dictionaries to store history for later plotting:\n",
    "        self.train_history = {\"acc\": [], \"loss\": []}\n",
    "        self.val_history = {\"acc\": [], \"loss\": []}\n",
    "\n",
    "    def forward(self, title: torch.Tensor, body: torch.Tensor) -> torch.Tensor:\n",
    "        # Obtain embeddings\n",
    "        title_embed = self.embedding(title)   # (batch, seq_len, embed_dim)\n",
    "        body_embed = self.embedding(body)\n",
    "        \n",
    "        # Shared bidirectional LSTM for title and body separately:\n",
    "        _, (title_hidden, _) = self.bilstm(title_embed)  # title_hidden: (num_layers*2, batch, hidd_dim)\n",
    "        _, (body_hidden, _) = self.bilstm(body_embed)      # body_hidden: (num_layers*2, batch, hidd_dim)\n",
    "        \n",
    "        # Aggregate hidden states by mean pooling over the layers dimension:\n",
    "        # Permute to (batch, num_layers*2, hidd_dim)\n",
    "        title_hidden = title_hidden.permute(1, 0, 2)\n",
    "        body_hidden = body_hidden.permute(1, 0, 2)\n",
    "        \n",
    "        # Mean pooling over the layer dimension\n",
    "        title_repr = title_hidden.mean(dim=1)  # (batch, hidd_dim)\n",
    "        body_repr = body_hidden.mean(dim=1)    # (batch, hidd_dim)\n",
    "        \n",
    "        # Fuse the representations (here we simply average them)\n",
    "        aggregated = (title_repr + body_repr) / 2  # (batch, hidd_dim)\n",
    "        \n",
    "        logits = self.classifier(aggregated)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits = self.forward(batch[\"title\"], batch[\"body\"])\n",
    "        loss = self.loss_fn(logits, batch[\"labels\"])\n",
    "        self._train_losses.append(loss)\n",
    "        self.train_acc.update(logits, batch[\"labels\"])\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits = self.forward(batch[\"title\"], batch[\"body\"])\n",
    "        loss = self.loss_fn(logits, batch[\"labels\"])\n",
    "        self._val_losses.append(loss)\n",
    "        self.val_acc.update(logits, batch[\"labels\"])\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        avg_loss = torch.stack(self._train_losses).mean() if self._train_losses else torch.tensor(0.0, device=self.device)\n",
    "        train_acc = self.train_acc.compute()\n",
    "        self.train_history[\"loss\"].append(avg_loss.item())\n",
    "        self.train_history[\"acc\"].append(train_acc.item())\n",
    "        self.log_dict({\"Epoch_Train_Loss\": avg_loss, \"Epoch_Train_Acc\": train_acc}, prog_bar=True)\n",
    "        print(f\"Train - Acc: {train_acc:.4f}, Loss: {avg_loss:.4f}\")\n",
    "        self.train_acc.reset()\n",
    "        self._train_losses.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_loss = torch.stack(self._val_losses).mean() if self._val_losses else torch.tensor(0.0, device=self.device)\n",
    "        val_acc = self.val_acc.compute()\n",
    "        self.val_history[\"loss\"].append(avg_loss.item())\n",
    "        self.val_history[\"acc\"].append(val_acc.item())\n",
    "        self.log_dict({\"Epoch_Val_Loss\": avg_loss, \"Epoch_Val_Acc\": val_acc}, prog_bar=True)\n",
    "        print(f\"Val - Acc: {val_acc:.4f}, Loss: {avg_loss:.4f}\")\n",
    "        self.val_acc.reset()\n",
    "        self._val_losses.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "# Instantiate the ablated model (without MHA)\n",
    "model = LitBiasModel(\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    num_classes=3,\n",
    "    embed_dim=300,\n",
    "    hidd_dim=200,\n",
    "    num_layers=2,\n",
    "    lr=1e-3\n",
    ")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T04:26:49.196885Z",
     "iopub.status.busy": "2025-02-28T04:26:49.196569Z",
     "iopub.status.idle": "2025-02-28T04:42:33.746098Z",
     "shell.execute_reply": "2025-02-28T04:42:33.745028Z",
     "shell.execute_reply.started": "2025-02-28T04:26:49.196861Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.4482, Loss: 1.0700\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa9b66b591542acb7a1337ad787bde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.6010, Loss: 0.9790\n",
      "Train - Acc: 0.6051, Loss: 0.8752\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.6427, Loss: 0.8195\n",
      "Train - Acc: 0.6364, Loss: 0.8355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.6435, Loss: 0.7997\n",
      "Train - Acc: 0.6640, Loss: 0.7777\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.6420, Loss: 0.8236\n",
      "Train - Acc: 0.6994, Loss: 0.7285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7225, Loss: 0.6661\n",
      "Train - Acc: 0.7149, Loss: 0.6966\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7025, Loss: 0.7615\n",
      "Train - Acc: 0.7362, Loss: 0.6607\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7409, Loss: 0.6363\n",
      "Train - Acc: 0.7566, Loss: 0.6154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7132, Loss: 0.6465\n",
      "Train - Acc: 0.7709, Loss: 0.5865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7452, Loss: 0.6137\n",
      "Train - Acc: 0.7852, Loss: 0.5597\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7422, Loss: 0.6226\n",
      "Train - Acc: 0.7901, Loss: 0.5523\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7240, Loss: 0.6716\n",
      "Train - Acc: 0.7726, Loss: 0.5861\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7548, Loss: 0.6120\n",
      "Train - Acc: 0.8009, Loss: 0.5247\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7356, Loss: 0.6219\n",
      "Train - Acc: 0.7972, Loss: 0.5263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7475, Loss: 0.6249\n",
      "Train - Acc: 0.8087, Loss: 0.4959\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7471, Loss: 0.5975\n",
      "Train - Acc: 0.8241, Loss: 0.4705\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7614, Loss: 0.5893\n",
      "Train - Acc: 0.8316, Loss: 0.4542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7334, Loss: 0.6412\n",
      "Train - Acc: 0.8435, Loss: 0.4277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7706, Loss: 0.6010\n",
      "Train - Acc: 0.8456, Loss: 0.4200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7653, Loss: 0.6763\n",
      "Train - Acc: 0.8601, Loss: 0.3937\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7601, Loss: 0.6933\n",
      "Train - Acc: 0.8686, Loss: 0.3735\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val - Acc: 0.7740, Loss: 0.6458\n",
      "Train - Acc: 0.8776, Loss: 0.3486\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "pl.seed_everything(42)\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"lit_bias_model\")\n",
    "\n",
    "# Early stopping callback remains the same (monitoring validation loss)\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    mode=\"min\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Change the monitor key to 'Epoch_Val_Acc'\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"Epoch_Val_Acc\",  # updated key\n",
    "    mode=\"max\",\n",
    "    save_top_k=1,\n",
    "    dirpath=\"checkpoints/\", \n",
    "    filename=\"best_model-{epoch:02d}-{Epoch_Val_Acc:.4f}\"\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    max_epochs=100,  # Increased epochs for potential improvement\n",
    "    logger=logger,\n",
    "    log_every_n_steps=10,\n",
    "    callbacks=[early_stop_callback, checkpoint_callback]\n",
    ")\n",
    "\n",
    "trainer.fit(model, data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6763,
     "sourceId": 9801,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2196935,
     "sourceId": 3670159,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
